{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Usage","text":""},{"location":"#install","title":"Install","text":"<pre><code>pip install deeplocalizer\n</code></pre> <p>or </p> <pre><code>uv add deeplocalizer\n</code></pre> <p>Import</p> <pre><code>from deeplocalizer import DeepLocalizer # or import other functions in API below\n</code></pre>"},{"location":"#example","title":"Example","text":"<p>An example using all of the core and visualization functions, see the face localization on Resnet example:  <code>resnet34_example.ipynb</code>.</p>"},{"location":"#api","title":"API","text":""},{"location":"#core","title":"Core","text":""},{"location":"#deeplocalizer.load_task","title":"load_task","text":"<pre><code>load_task(filename: str) -&gt; tuple[DataFrame, DataFrame]\n</code></pre> Source code in <code>deeplocalizer/deeplocalizer.py</code> <pre><code>def load_task(filename: str) -&gt; tuple[pd.DataFrame, pd.DataFrame]:\n    assert os.path.exists(filename), \"task file must exist\"\n\n    df = pd.read_parquet(filename)\n    task = df[df[\"validation\"] == False]\n    validation = df[df[\"validation\"] == True]\n    return task, validation\n</code></pre>"},{"location":"#deeplocalizer.DeepLocalizer","title":"DeepLocalizer","text":"<pre><code>DeepLocalizer(task: DataFrame, layers_activations: list[Module], model_forward: ModelForwardFunc, save_activations_func: SaveActivationsFunc = default_save_activations, ablate_activations_func: AblateActivationsFunc = default_flat_idxs_ablate, ablate_factor: float = 0.0, batch_size=32)\n</code></pre> Source code in <code>deeplocalizer/deeplocalizer.py</code> <pre><code>def __init__(\n    self,\n    task: pd.DataFrame,\n    layers_activations: list[torch.nn.Module],\n    model_forward: ModelForwardFunc,\n    save_activations_func: SaveActivationsFunc = default_save_activations,\n    ablate_activations_func: AblateActivationsFunc = default_flat_idxs_ablate,\n    ablate_factor: float = 0.0,\n    batch_size=32,\n):\n    self.layers_activations = layers_activations\n    self.task = task\n    self.model_forward = model_forward\n    self.save_activations_func = save_activations_func\n    self.ablate_activations_func = ablate_activations_func\n    self.ablate_factor = ablate_factor\n    self.batch_size = batch_size\n    self.activations = None\n</code></pre>"},{"location":"#deeplocalizer.DeepLocalizer.compute_activations","title":"compute_activations","text":"<pre><code>compute_activations() -&gt; DeepLocalizer\n</code></pre> Source code in <code>deeplocalizer/deeplocalizer.py</code> <pre><code>def compute_activations(self) -&gt; DeepLocalizer:\n    print(\"[DeepLocalizer] Computing Activations\")\n    self.activations = compute_task_activations(\n        df=self.task,\n        model_forward=self.model_forward,\n        layers_activations=self.layers_activations,\n        batch_size=self.batch_size,\n    )\n    return self\n</code></pre>"},{"location":"#deeplocalizer.DeepLocalizer.load_activations","title":"load_activations","text":"<pre><code>load_activations(filename: str, device: device = 'cpu') -&gt; DeepLocalizer\n</code></pre> Source code in <code>deeplocalizer/deeplocalizer.py</code> <pre><code>def load_activations(\n    self, filename: str, device: torch.device = \"cpu\"\n) -&gt; DeepLocalizer:\n    self.activations = load_activations_from_disk(filename, device)\n    return self\n</code></pre>"},{"location":"#deeplocalizer.DeepLocalizer.save_activations","title":"save_activations","text":"<pre><code>save_activations(filename: str)\n</code></pre> Source code in <code>deeplocalizer/deeplocalizer.py</code> <pre><code>def save_activations(self, filename: str):\n    self.assert_activations()\n    save_activations_to_disk(self.activations, filename)\n</code></pre>"},{"location":"#deeplocalizer.DeepLocalizer.top_percent_activations","title":"top_percent_activations","text":"<pre><code>top_percent_activations(top_percent: float, transform=lambda x: abs(x)) -&gt; tuple[list[int], list[int]]\n</code></pre> Source code in <code>deeplocalizer/deeplocalizer.py</code> <pre><code>def top_percent_activations(\n    self, top_percent: float, transform=lambda x: torch.abs(x)\n) -&gt; tuple[list[int], list[int]]:\n    self.assert_activations()\n    return top_percent_global(_map(transform, self.activations), top_percent)\n</code></pre>"},{"location":"#deeplocalizer.DeepLocalizer.regular_model_forward","title":"regular_model_forward","text":"<pre><code>regular_model_forward(df: DataFrame = None) -&gt; tuple[ModelForwardReturn, ModelForwardReturn]\n</code></pre> Source code in <code>deeplocalizer/deeplocalizer.py</code> <pre><code>@torch.no_grad()\ndef regular_model_forward(\n    self, df: pd.DataFrame = None\n) -&gt; tuple[ModelForwardReturn, ModelForwardReturn]:\n    self.assert_activations()\n\n    if df is None:\n        df = self.task\n\n    positive = df[df[\"positive\"] == True]\n    control = df[df[\"positive\"] == False]\n\n    print(\"[DeepLocalizer] Computing Model Forward\")\n    return regular_inference(\n        positive[\"data\"],\n        self.model_forward,\n        self.batch_size,\n    ), regular_inference(\n        control[\"data\"],\n        self.model_forward,\n        self.batch_size,\n    )\n</code></pre>"},{"location":"#deeplocalizer.DeepLocalizer.ablate_model_forward","title":"ablate_model_forward","text":"<pre><code>ablate_model_forward(ablate_activations: list[AblateIdxs], df: DataFrame = None) -&gt; tuple[ModelForwardReturn, ModelForwardReturn]\n</code></pre> Source code in <code>deeplocalizer/deeplocalizer.py</code> <pre><code>@torch.no_grad()\ndef ablate_model_forward(\n    self,\n    ablate_activations: list[AblateIdxs],\n    df: pd.DataFrame = None,\n) -&gt; tuple[ModelForwardReturn, ModelForwardReturn]:\n    self.assert_activations()\n\n    if df is None:\n        df = self.task\n\n    print(\"[DeepLocalizer] Computing Model Forward ABLATED\")\n    with AblateTorchModel(\n        layers=self.layers_activations,\n        to_ablate=ablate_activations,\n        scalar=self.ablate_factor,\n        ablate_activations=self.ablate_activations_func,\n    ):\n        return self.regular_model_forward(df)\n</code></pre>"},{"location":"#visualization","title":"Visualization","text":""},{"location":"#deeplocalizer.visualize_activations","title":"visualize_activations","text":"<pre><code>visualize_activations(activations: list[Tensor], grid=None, cmap='viridis')\n</code></pre> Source code in <code>deeplocalizer/deeplocalizer.py</code> <pre><code>def visualize_activations(activations: list[torch.Tensor], grid=None, cmap=\"viridis\"):\n    if grid is None:\n        # first combine all the layers so can do argpartition\n        for i, a in enumerate(activations):\n            plt.title(f\"Layer {i}\")\n            plt.imshow(squarify(a), cmap=cmap, aspect=\"auto\")\n            plt.colorbar()\n            plt.show()\n    else:\n        fig, axes = plt.subplots(*grid, figsize=(16, 9))\n        fig.suptitle(\"Absolute activations\")\n        for i, ax in enumerate(axes.flat):\n            a = activations[i]\n            im = ax.imshow(squarify(a), cmap=cmap, aspect=\"auto\")\n            ax.set_title(f\"Layer {i}\")\n            plt.colorbar(im, ax=ax)\n            no_ticks(ax)\n        plt.show()\n</code></pre>"},{"location":"#deeplocalizer.visualize_top_per_layer","title":"visualize_top_per_layer","text":"<pre><code>visualize_top_per_layer(top_idxs, activations, title='Percentage Top activations per layer')\n</code></pre> Source code in <code>deeplocalizer/deeplocalizer.py</code> <pre><code>def visualize_top_per_layer(\n    top_idxs, activations, title=\"Percentage Top activations per layer\"\n):\n    import seaborn as sns\n    import numpy as np\n\n    total_lengths = [prod(a.shape) for a in activations]\n    percentages = (\n        np.array([len(top_idxs[i]) / l for i, l in enumerate(total_lengths)]).reshape(\n            (-1, 1)\n        )\n        * 100\n    )\n    labels = np.array([f\"{p[0]:.2f}%\" for p in percentages]).reshape(percentages.shape)\n\n    plt.figure(figsize=(4, 6))\n    ax = sns.heatmap(\n        percentages,\n        cmap=\"inferno\",\n        annot=labels,\n        annot_kws={\"fontsize\": 10},\n        fmt=\"s\",\n        linecolor=\"white\",\n        linewidths=1,\n    )\n    ax.set(\n        title=title,\n        xticklabels=[],\n        xticks=[],\n        ylabel=\"Layers\",\n    )\n\n    plt.show()\n</code></pre>"},{"location":"#deeplocalizer.visualize_top_activations","title":"visualize_top_activations","text":"<pre><code>visualize_top_activations(top_idxs, top_values, activations, grid=(4, 4), title='Top % activations showing')\n</code></pre> Source code in <code>deeplocalizer/deeplocalizer.py</code> <pre><code>def visualize_top_activations(\n    top_idxs, top_values, activations, grid=(4, 4), title=\"Top % activations showing\"\n):\n    fig, axes = plt.subplots(*grid, figsize=(16, 9))\n    fig.suptitle(title)\n    for i, ax in enumerate(axes.flat):\n        a = activations[i]\n        top_idx = top_idxs[i]\n        top_value = top_values[i]\n        visualize_top_activation(ax, top_idx, top_value, a, title=f\"Layer {i}\")\n    plt.show()\n</code></pre>"},{"location":"#types","title":"Types","text":""},{"location":"#deeplocalizer.ModelForwardFunc","title":"ModelForwardFunc  <code>module-attribute</code>","text":"<pre><code>ModelForwardFunc = Callable[[list[Any]], ModelForwardReturn]\n</code></pre>"},{"location":"#deeplocalizer.ModelForwardReturn","title":"ModelForwardReturn  <code>module-attribute</code>","text":"<pre><code>ModelForwardReturn = Any | tuple\n</code></pre>"},{"location":"#deeplocalizer.SaveActivationsFunc","title":"SaveActivationsFunc  <code>module-attribute</code>","text":"<pre><code>SaveActivationsFunc = Callable[[Tensor], Tensor]\n</code></pre>"},{"location":"#deeplocalizer.AblateActivationsFunc","title":"AblateActivationsFunc  <code>module-attribute</code>","text":"<pre><code>AblateActivationsFunc = Callable[[Tensor, AblateIdxs, float], Tensor]\n</code></pre>"},{"location":"#deeplocalizer.AblateIdxs","title":"AblateIdxs  <code>module-attribute</code>","text":"<pre><code>AblateIdxs = Tensor | list[int]\n</code></pre>"}]}